{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ML_hatespeech_detection.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN8rRyf72VpiEwfFKausEiL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["#Imports\n","!pip install emoji\n","import emoji\n","from sklearn.model_selection import train_test_split \n","from sklearn.utils import shuffle\n","from sklearn.metrics import classification_report, plot_confusion_matrix, accuracy_score\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","from sklearn.svm import SVC\n","from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n","from sklearn.linear_model import LogisticRegression\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","import json\n","import numpy as np\n","import warnings\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"KnaiauIPXPgr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656488477659,"user_tz":-120,"elapsed":7151,"user":{"displayName":"ELA KATHERINE SHEPHERD AREVALO","userId":"06530263046701412488"}},"outputId":"b338fbc0-2ad6-4a0f-e5dd-0da9c692eb82"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting emoji\n","  Downloading emoji-1.7.0.tar.gz (175 kB)\n","\u001b[K     |████████████████████████████████| 175 kB 26.5 MB/s \n","\u001b[?25hBuilding wheels for collected packages: emoji\n","  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171046 sha256=3bf0cec846d4dd1e7bf85d56d578200444a9fd02877c43f00479f4a20f56f4cf\n","  Stored in directory: /root/.cache/pip/wheels/8a/4e/b6/57b01db010d17ef6ea9b40300af725ef3e210cb1acfb7ac8b6\n","Successfully built emoji\n","Installing collected packages: emoji\n","Successfully installed emoji-1.7.0\n"]}]},{"cell_type":"code","source":["from google.colab import drive \n","drive.mount('/content/drive')"],"metadata":{"id":"guAPDPIOUL6e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656488497312,"user_tz":-120,"elapsed":19667,"user":{"displayName":"ELA KATHERINE SHEPHERD AREVALO","userId":"06530263046701412488"}},"outputId":"54e62538-b957-438b-9f66-aebf0c1d6608"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["##Stop words and vectorizing\n","https://github.com/6/stopwords-json\n","\n","TfidfVectorizer or countvectorizer? now using CV, could be other type too"],"metadata":{"id":"22hJtrcDTK0J"}},{"cell_type":"markdown","source":["#NAIVE BAYES\n"],"metadata":{"id":"NYLAfnz5HHpK"}},{"cell_type":"code","source":["def naive_bayes(i, balance, lang, emo_hash, test, nbtype, print_metrics, vectorizer):\n","  if i == 0:#\n","    i = 1#\n","  if balance:#\n","    #we save our txt files in a general path, I later save them into their specific folders\n","    path = \"/content/drive/MyDrive/TFG/data/accuracy_data/NB_\" + lang + \"_\" + emo_hash + \"_\" + str(100-(test*100)) + str(test*100) +\"TrainTest_\" + nbtype + \"_\" + vectorizer + \"_BALANCED.txt\"#\n","  else:#\n","    path = \"/content/drive/MyDrive/TFG/data/accuracy_data/NB_\" + lang + \"_\" + emo_hash + \"_\" + str(100-(test*100)) + str(test*100) +\"TrainTest_\" + nbtype + \"_\" + vectorizer + \"_NOT_BALANCED.txt\"#\n","  acc_file = open(path,\"w+\") #\n","  for x in range(i):#\n","    #Data loading---------------------------------GENERAL--CODE-----------------------------------------------\n","    df = pd.read_csv('/content/drive/MyDrive/TFG/data/final_data/' + emo_hash + '_' + lang + '_data.csv', encoding='utf8', engine='python')\n","    #Final row cleansing\n","    df = df[(df['hate speech'] == 0) | (df['hate speech'] == 1)]\n","    df = df.dropna()\n","    df = shuffle(df)\n","    #Balancing data\n","    if balance: \n","      pos_rows = len(df[df[\"hate speech\"] == True].index)\n","      fraction_to_delete = 1 - (pos_rows/ (df.shape[0]-pos_rows))\n","      df = df.drop(df[df['hate speech'] == 0].sample(frac=fraction_to_delete).index)\n","    #Train and test split\n","    X, y = df.text.fillna(' '), df[\"hate speech\"]\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test)\n","    #Vectorizing\n","    with open(\"/content/drive/MyDrive/TFG/data/stopwords/\" + lang + \"_stopwords.json\", \"r\") as f:\n","      json_text = f.read()\n","    stopwords = list(json.loads(json_text))\n","    if vectorizer == \"CountVectorizer\":\n","      vect = CountVectorizer(stop_words = stopwords, binary = True)\n","    else:\n","      vect = TfidfVectorizer(stop_words = stopwords, binary = True) # tfidf here\n","    X_train_vect = vect.fit_transform(X_train)\n","    X_test_vect = vect.transform(X_test)\n","    #Model building---------------------------------GENERAL--CODE-----------------------------------------------\n","    if nbtype == \"Bernoulli\":\n","      model = BernoulliNB()\n","    else:\n","      model = MultinomialNB()\n","    model.fit(X_train_vect, y_train)\n","    #Plot printing\n","    if print_metrics:\n","      y_pred = model.predict(X_test_vect)\n","      acc_file.write(str(accuracy_score(y_test, y_pred) * 100) + \"\\n\")#\n","      # print(classification_report(y_test,y_pred))\n","      # print(\"-------------------------------------------------------\")\n","      print(\"Accuracy score for Naive Bayes is: \", accuracy_score(y_test, y_pred) * 100, '%')\n","      # print(\"-------------------------------------------------------\")\n","      # #cmap options: YlOrRd, GnBu, RdPu, YlGn\n","      # plot_confusion_matrix(model, X_test_vect, y_test, normalize='true', cmap =\"GnBu\")\n","  acc_file.close()#\n","  return model, vect"],"metadata":{"id":"eZ5iNKM9XS7w","executionInfo":{"status":"ok","timestamp":1656488498297,"user_tz":-120,"elapsed":9,"user":{"displayName":"ELA KATHERINE SHEPHERD AREVALO","userId":"06530263046701412488"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["#SUPPORT VECTOR MACHINES\n","Using SVM classifiers for text classification tasks might be a really good idea, especially if the training data available is not much (~ a couple of thousand tagged samples)."],"metadata":{"id":"DFWGClteHCOc"}},{"cell_type":"code","source":["def support_vector_machine(i, balance, lang, emo_hash, test, kernel, c, print_metrics, vectorizer):\n","  if i == 0:#\n","    i = 1#\n","  if balance:#\n","    #we save our txt files in a general path, I later save them into their specific folders\n","    path = \"/content/drive/MyDrive/TFG/data/accuracy_data/SVM_\" + lang + \"_\" + emo_hash + \"_\" + str(100-(test*100)) + str(test*100) +\"TrainTest_\" + kernel + \"Kernel_\" + str(c) + \"C_\" + vectorizer + \"_BALANCED.txt\"#\n","  else:#\n","    path = \"/content/drive/MyDrive/TFG/data/accuracy_data/SVM_\" + lang + \"_\" + emo_hash + \"_\" + str(100-(test*100)) + str(test*100) +\"TrainTest_\" + kernel + \"Kernel_\" + str(c) + \"C_\" + vectorizer + \"_NOT_BALANCED.txt\"#\n","  acc_file = open(path,\"w+\") #\n","  for x in range(i):#\n","    #Data loading---------------------------------GENERAL--CODE-----------------------------------------------\n","    df = pd.read_csv('/content/drive/MyDrive/TFG/data/final_data/' + emo_hash + '_' + lang + '_data.csv', encoding='utf8', engine='python')\n","    #Final row cleansing\n","    df = df[(df['hate speech'] == 0) | (df['hate speech'] == 1)]\n","    df = df.dropna()\n","    df = shuffle(df)\n","    #Balancing data\n","    if balance: \n","      pos_rows = len(df[df[\"hate speech\"] == True].index)\n","      fraction_to_delete = 1 - (pos_rows/ (df.shape[0]-pos_rows))\n","      df = df.drop(df[df['hate speech'] == 0].sample(frac=fraction_to_delete).index)\n","    #Train and test split\n","    X, y = df.text.fillna(' '), df[\"hate speech\"]\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test)\n","    #Vectorizing\n","    with open(\"/content/drive/MyDrive/TFG/data/stopwords/\" + lang + \"_stopwords.json\", \"r\") as f:\n","      json_text = f.read()\n","    stopwords = list(json.loads(json_text))\n","    if vectorizer == \"CountVectorizer\":\n","      vect = CountVectorizer(stop_words = stopwords, binary = True)\n","    else:\n","      vect = TfidfVectorizer(stop_words = stopwords, binary = True) # tfidf here\n","    X_train_vect = vect.fit_transform(X_train)\n","    X_test_vect = vect.transform(X_test)\n","    #Model building---------------------------------GENERAL--CODE-----------------------------------------------\n","    model = SVC(kernel=kernel, C=c)\n","    model.fit(X_train_vect, y_train)\n","    #Plot printing\n","    if print_metrics:\n","      y_pred = model.predict(X_test_vect)\n","      acc_file.write(str(accuracy_score(y_test, y_pred) * 100) + \"\\n\")#\n","      # print(classification_report(y_test,y_pred))\n","      # print(\"-------------------------------------------------------\")\n","      print(\"Accuracy score for SVC is: \", accuracy_score(y_test, y_pred) * 100, '%')\n","      # print(\"-------------------------------------------------------\")\n","      # #cmap options: YlOrRd, GnBu, RdPu, YlGn\n","      # plot_confusion_matrix(model, X_test_vect, y_test, normalize='true', cmap =\"YlOrRd\")\n","  acc_file.close()#\n","  return model, vect"],"metadata":{"id":"nPVaJ7veUb_m","executionInfo":{"status":"ok","timestamp":1656488498300,"user_tz":-120,"elapsed":11,"user":{"displayName":"ELA KATHERINE SHEPHERD AREVALO","userId":"06530263046701412488"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["#LOGISTIC REGRESSION\n"],"metadata":{"id":"iXV_qvLYHFZQ"}},{"cell_type":"code","source":["def logistic_regression(i, balance, lang, emo_hash, test, solver, c, print_metrics, vectorizer):\n","  if i == 0:#\n","    i = 1#\n","  if balance:#\n","    #we save our txt files in a general path, I later save them into their specific folders\n","    path = \"/content/drive/MyDrive/TFG/data/accuracy_data/LR_\" + lang + \"_\" + emo_hash + \"_\" + str(100-(test*100)) + str(test*100) +\"TrainTest_\" + solver + \"Solver_\" + str(c) + \"C_\" + vectorizer + \"_BALANCED.txt\"#\n","  else:#\n","    path = \"/content/drive/MyDrive/TFG/data/accuracy_data/LR_\" + lang + \"_\" + emo_hash + \"_\" + str(100-(test*100)) + str(test*100) +\"TrainTest_\" + solver + \"Solver_\" + str(c) + \"C_\" + vectorizer + \"_NOT_BALANCED.txt\"#\n","  acc_file = open(path,\"w+\") #\n","  for x in range(i):#\n","    #Data loading---------------------------------GENERAL--CODE-----------------------------------------------\n","    df = pd.read_csv('/content/drive/MyDrive/TFG/data/final_data/' + emo_hash + '_' + lang + '_data.csv', encoding='utf8', engine='python')\n","    #Final row cleansing\n","    df = df[(df['hate speech'] == 0) | (df['hate speech'] == 1)]\n","    df = df.dropna()\n","    df = shuffle(df)\n","    #Balancing data\n","    if balance: \n","      pos_rows = len(df[df[\"hate speech\"] == True].index)\n","      fraction_to_delete = 1 - (pos_rows/ (df.shape[0]-pos_rows))\n","      df = df.drop(df[df['hate speech'] == 0].sample(frac=fraction_to_delete).index)\n","    #Train and test split\n","    X, y = df.text.fillna(' '), df[\"hate speech\"]\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test)\n","    #Vectorizing\n","    with open(\"/content/drive/MyDrive/TFG/data/stopwords/\" + lang + \"_stopwords.json\", \"r\") as f:\n","      json_text = f.read()\n","    stopwords = list(json.loads(json_text))\n","    if vectorizer == \"CountVectorizer\":\n","      vect = CountVectorizer(stop_words = stopwords, binary = True)\n","    else:\n","      vect = TfidfVectorizer(stop_words = stopwords, binary = True) # tfidf here\n","    X_train_vect = vect.fit_transform(X_train)\n","    X_test_vect = vect.transform(X_test)\n","    #Model building---------------------------------GENERAL--CODE-----------------------------------------------\n","    model = LogisticRegression(solver=solver, C=c)\n","    model.fit(X_train_vect, y_train)\n","    #Plot printing\n","    if print_metrics:\n","      y_pred = model.predict(X_test_vect)\n","      acc_file.write(str(accuracy_score(y_test, y_pred) * 100) + \"\\n\")#\n","      # print(classification_report(y_test,y_pred))\n","      # print(\"-------------------------------------------------------\")\n","      print(\"Accuracy score for Logistic Regression is: \", accuracy_score(y_test, y_pred) * 100, '%')\n","      # print(\"-------------------------------------------------------\")\n","      # #cmap options: YlOrRd, GnBu, RdPu, YlGn\n","      # plot_confusion_matrix(model, X_test_vect, y_test, normalize='true', cmap =\"RdPu\")\n","  acc_file.close()#\n","  return model, vect"],"metadata":{"id":"hK4wM-TxQBFy","executionInfo":{"status":"ok","timestamp":1656488498302,"user_tz":-120,"elapsed":13,"user":{"displayName":"ELA KATHERINE SHEPHERD AREVALO","userId":"06530263046701412488"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["------------------------------------------------------------------------\n","#Accuracy checker and hate speech detectors"],"metadata":{"id":"EaBLHdk3y0ts"}},{"cell_type":"code","source":["#@title 1. Choose a model and language\n","\n","Language = 'Spanish'  #@param [\"Spanish\", \"Italian\", \"Portuguese\", \"English\"]\n","\n","map_lang_data = {\n","    'Spanish':\n","        'spanish',\n","    'Italian':\n","        'italian',\n","    'Portuguese':\n","        'portuguese',\n","    'English':\n","        'english',\n","}\n","\n","Emojis_Hashtags = 'No emojis or hashtags'  #@param [\"All emojis and hashtags\", \"Filtered emojis and hashtags\", \"No emojis or hashtags\"]\n","\n","map_emojhash_data = {\n","    'All emojis and hashtags':\n","        'mantained',\n","    'Filtered emojis and hashtags':\n","        'filtered',\n","    'No emojis or hashtags':\n","        'removed',\n","}\n","\n","Train_Test_Split = '70/30'  #@param ['60/40', '70/30', '80/20']\n","\n","map_test_split = {\n","    '60/40':\n","        0.4,\n","    '70/30':\n","        0.3,\n","    '80/20':\n","        0.2,\n","}\n","\n","Model = 'SVM linear kernel large C'  #@param [\"Bernoulli NB\", \"Multinomial NB\", \"SVM linear kernel small C\", \"SVM linear kernel standard C\", \"SVM linear kernel large C\", \"SVM RBF kernel small C\", \"SVM RBF kernel standard C\", \"SVM RBF kernel large C\", \"LR liblinear solver small C\", \"LR liblinear solver standard C\",\"LR liblinear solver large C\", \"LR lbfgs solver small C\", \"LR lbfgs solver standard C\", \"LR lbfgs solver large C\"]\n","\n","TF_IDF = False #@param {type:\"boolean\"}\n","Print_model_metrics = True #@param {type:\"boolean\"}\n","Test_Iterations = 30 #@param {type:\"slider\", min:1, max:50, step:1}\n","Balance_data = True #@param {type:\"boolean\"}\n","\n","map_vectorizer = {\n","    True:\n","        \"TfidfVectorizer\",\n","    False:\n","        \"CountVectorizer\",\n","}\n","\n","lang = map_lang_data[Language]\n","emo_hash = map_emojhash_data[Emojis_Hashtags]\n","test = map_test_split[Train_Test_Split]\n","vectorizer = map_vectorizer[TF_IDF]\n","if TF_IDF:\n","  vectorizer_word = \"with\"\n","else:\n","  vectorizer_word = \"without\"\n","\n","print((Language + \" data with \" + Emojis_Hashtags +\" using model \" + Model + \", \" + vectorizer_word + \" TF-IDF and train/test split of \" + Train_Test_Split).upper())\n","print(\"-------------------------------------------------------------------------------------------------------------------------------\")\n","\n","if Model == \"SVM linear kernel small C\":\n","  chosen_model, vect = support_vector_machine(Test_Iterations, Balance_data, lang, emo_hash, test, \"linear\", 0.1, Print_model_metrics, vectorizer)\n","elif Model == \"SVM linear kernel standard C\":\n","  chosen_model, vect = support_vector_machine(Test_Iterations, Balance_data, lang, emo_hash, test, \"linear\", 1, Print_model_metrics, vectorizer)\n","elif Model == \"SVM linear kernel large C\":\n","  chosen_model, vect = support_vector_machine(Test_Iterations, Balance_data, lang, emo_hash, test, \"linear\", 10, Print_model_metrics, vectorizer)\n","elif Model == \"SVM RBF kernel small C\":\n","  chosen_model, vect = support_vector_machine(Test_Iterations, Balance_data, lang, emo_hash, test, \"rbf\", 0.1, Print_model_metrics, vectorizer)\n","elif Model == \"SVM RBF kernel standard C\":\n","  chosen_model, vect = support_vector_machine(Test_Iterations, Balance_data, lang, emo_hash, test, \"rbf\", 1, Print_model_metrics, vectorizer)\n","elif Model == \"SVM RBF kernel large C\":\n","  chosen_model, vect = support_vector_machine(Test_Iterations, Balance_data, lang, emo_hash, test, \"rbf\", 10, Print_model_metrics, vectorizer)\n","\n","elif Model == \"Bernoulli NB\":\n","  chosen_model, vect = naive_bayes(Test_Iterations, Balance_data, lang, emo_hash, test, \"Bernoulli\", Print_model_metrics, vectorizer)\n","elif Model == \"Multinomial NB\":\n","  chosen_model, vect = naive_bayes(Test_Iterations, Balance_data, lang, emo_hash, test, \"Multinomial\", Print_model_metrics, vectorizer)\n","\n","elif Model == \"LR liblinear solver small C\":\n","  chosen_model, vect = logistic_regression(Test_Iterations, Balance_data, lang, emo_hash, test, \"liblinear\", 0.1, Print_model_metrics, vectorizer)\n","elif Model == \"LR liblinear solver standard C\":\n","  chosen_model, vect = logistic_regression(Test_Iterations, Balance_data, lang, emo_hash, test, \"liblinear\", 1, Print_model_metrics, vectorizer)\n","elif Model == \"LR liblinear solver large C\":\n","  chosen_model, vect = logistic_regression(Test_Iterations, Balance_data, lang, emo_hash, test, \"liblinear\", 10, Print_model_metrics, vectorizer)\n","elif Model == \"LR lbfgs solver small C\":\n","  chosen_model, vect = logistic_regression(Test_Iterations, Balance_data, lang, emo_hash, test, \"lbfgs\", 0.1, Print_model_metrics, vectorizer)\n","elif Model == \"LR lbfgs solver standard C\":\n","  chosen_model, vect = logistic_regression(Test_Iterations, Balance_data, lang, emo_hash, test, \"lbfgs\", 1, Print_model_metrics, vectorizer)\n","elif Model == \"LR lbfgs solver large C\":\n","  chosen_model, vect = logistic_regression(Test_Iterations, Balance_data, lang, emo_hash, test, \"lbfgs\", 10, Print_model_metrics, vectorizer)"],"metadata":{"id":"sdllLCBZSd8o","cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656525022069,"user_tz":-120,"elapsed":381338,"user":{"displayName":"ELA KATHERINE SHEPHERD AREVALO","userId":"06530263046701412488"}},"outputId":"e161e289-d1e2-4b6a-a963-bfc5bf5a5712"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["SPANISH DATA WITH NO EMOJIS OR HASHTAGS USING MODEL SVM LINEAR KERNEL LARGE C, WITHOUT TF-IDF AND TRAIN/TEST SPLIT OF 70/30\n","-------------------------------------------------------------------------------------------------------------------------------\n","Accuracy score for SVC is:  70.38473009245452 %\n","Accuracy score for SVC is:  69.28124067998806 %\n","Accuracy score for SVC is:  69.01282433641515 %\n","Accuracy score for SVC is:  70.23560990158067 %\n","Accuracy score for SVC is:  70.23560990158067 %\n","Accuracy score for SVC is:  70.44437816880405 %\n","Accuracy score for SVC is:  70.26543393975544 %\n","Accuracy score for SVC is:  69.43036087086192 %\n","Accuracy score for SVC is:  70.29525797793022 %\n","Accuracy score for SVC is:  68.4759916492693 %\n","Accuracy score for SVC is:  70.62332239785268 %\n","Accuracy score for SVC is:  70.1163137488816 %\n","Accuracy score for SVC is:  69.96719355800775 %\n","Accuracy score for SVC is:  70.20578586340591 %\n","Accuracy score for SVC is:  70.20578586340591 %\n","Accuracy score for SVC is:  69.28124067998806 %\n","Accuracy score for SVC is:  70.56367432150313 %\n","Accuracy score for SVC is:  69.99701759618252 %\n","Accuracy score for SVC is:  69.01282433641515 %\n","Accuracy score for SVC is:  70.35490605427975 %\n","Accuracy score for SVC is:  70.23560990158067 %\n","Accuracy score for SVC is:  68.41634357291977 %\n","Accuracy score for SVC is:  70.0268416343573 %\n","Accuracy score for SVC is:  69.19176856546376 %\n","Accuracy score for SVC is:  69.04264837458992 %\n","Accuracy score for SVC is:  67.93915896212347 %\n","Accuracy score for SVC is:  69.13212048911423 %\n","Accuracy score for SVC is:  69.66895317626006 %\n","Accuracy score for SVC is:  69.75842529078437 %\n","Accuracy score for SVC is:  70.29525797793022 %\n"]}]},{"cell_type":"code","source":["#@title 2. Write some text to see if it contains hate speech...\n","text = \"\" #@param {type:\"string\"}\n","text = text.encode('utf-16','surrogatepass').decode('utf-16')\n","#demojize possible emojis\n","emo_full_list = ''.join(c for c in text if c in emoji.UNICODE_EMOJI['en'])\n","emo_unique_list = np.unique(list(emo_full_list))\n","for k in emo_unique_list:\n","    text = text.replace(k, \" \" + emoji.demojize(k) + \" \")\n","\n","prediction = chosen_model.predict(vect.transform([text]))\n","\n","if prediction == 1 or prediction == \"hate speech\":\n","  print(\"YES, This text contains hate speech\")\n","else:\n","  print(\"NO, This text does not contain hate speech\")"],"metadata":{"id":"an79S9M4ZVdx","cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655826315698,"user_tz":-120,"elapsed":216,"user":{"displayName":"ELA KATHERINE SHEPHERD AREVALO","userId":"06530263046701412488"}},"outputId":"616ecfd9-f067-42b0-9e31-18e7d1073839"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["YES, This text contains hate speech\n"]}]}]}