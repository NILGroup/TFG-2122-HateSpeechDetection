{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Acuracy_calc.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOAtwwoiyhGD/Iopo3ExoaD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"w6ADwCHgO8RX"},"outputs":[],"source":["import statistics \n","import pandas as pd"]},{"cell_type":"code","source":["from google.colab import drive \n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_e-fjJnIPKwF","executionInfo":{"status":"ok","timestamp":1656267637967,"user_tz":-120,"elapsed":78708,"user":{"displayName":"ELA KATHERINE SHEPHERD AREVALO","userId":"06530263046701412488"}},"outputId":"e526cb1e-c0f7-4362-b1d9-3347e37795cf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["df = pd.read_csv('/content/drive/MyDrive/TFG/data/accuracy_data/All_accuracy_std_deviation.csv', encoding='utf8', engine='python')"],"metadata":{"id":"sHq-UVrbQ5AM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def emojisHashtagsFile(txt):\n","  if txt == \"All\":\n","    return \"mantained\"\n","  elif txt == \"Filtered\":\n","    return \"filtered\"\n","  elif txt == \"No\":\n","    return \"removed\"\n","\n","def trainTestFile(txt):\n","  if txt == \"60/40\":\n","    return \"60.040.0\"\n","  elif txt == \"70/30\":\n","    return \"70.030.0\"\n","  elif txt == \"80/20\":\n","    return \"80.020.0\"\n","\n","def modelFile(txt):\n","  if txt == \"Naive Bayes\":\n","    return \"NB\"\n","  elif txt == \"LR\":\n","    return \"LR\"\n","  elif txt == \"SVM\":\n","    return \"SVM\"\n","\n","def modelSpecificationsFile(txt): \n","  if txt == \"Multinomial\":\n","    return \"Multinomial\"\n","  elif txt == \"Bernoulli\":\n","    return \"Bernoulli\"\n","  elif txt == \"Linear kernel, small C\":\n","    return \"linearKernel_0.1C\"\n","  elif txt == \"Linear kernel, standard C\":\n","    return \"linearKernel_1C\"\n","  elif txt == \"Linear kernel, large C\":\n","    return \"linearKernel_10C\"\n","  elif txt == \"RBF kernel, small C\":\n","    return \"rbfKernel_0.1C\"\n","  elif txt == \"RBF kernel, standard C\":\n","    return \"rbfKernel_1C\"\n","  elif txt == \"RBF kernel, large C\":\n","    return \"rbfKernel_10C\"\n","  elif txt == \"Liblinear solver, small C\":\n","    return \"liblinearSolver_0.1C\"\n","  elif txt == \"Liblinear solver, standard C\":\n","    return \"liblinearSolver_1C\"\n","  elif txt == \"Liblinear solver, large C\":\n","    return \"liblinearSolver_10C\"\n","  elif txt == \"Lbfgs solver, small C\":\n","    return \"lbfgsSolver_0.1C\"\n","  elif txt == \"Lbfgs solver, standard C\":\n","    return \"lbfgsSolver_1C\"\n","  elif txt == \"Lbfgs solver, large C\":\n","    return \"lbfgsSolver_10C\"\n","\n","def vectorizerFile(txt):\n","  if txt == \"Yes\":\n","    return \"TfidfVectorizer\"\n","  elif txt == \"No\":\n","    return \"CountVectorizer\"\n","\n","def balancedFile(txt):\n","  if txt == \"Yes\":\n","    return \"BALANCED\"\n","  elif txt == \"No\":\n","    return \"NOT_BALANCED\""],"metadata":{"id":"0zCXu1DgYDEQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for idx, row in df.iterrows():\n","#---------------------SET_PATH-------------------------------\n","  emojis_hashtags_file = emojisHashtagsFile(df['Emoji&hashtag'][idx])\n","  train_test_file = trainTestFile(df['Train/test'][idx])\n","  model_file = modelFile(df['Model'][idx])\n","  model_specifications_file = modelSpecificationsFile(df['Model_Specification'][idx])\n","  vectorizer_file = vectorizerFile(df['TF-IDF'][idx])\n","  balanced_file = balancedFile(df['Balance'][idx])\n","#------------------------------------------------------------\n","  path = \"/content/drive/MyDrive/TFG/data/accuracy_data/\"+ df['Language'][idx] +\"/\"+ df['Emoji&hashtag'][idx] +\"_emojis/\"+ df['Train/test'][idx] +\"TT/\"+ model_file +\"_\"+ df['Language'][idx].lower() +\"_\"+ emojis_hashtags_file +\"_\"+ train_test_file +\"TrainTest_\"+ model_specifications_file +\"_\"+ vectorizer_file +\"_\"+ balanced_file +\".txt\"\n","  with open(path) as f:\n","    lines = f.readlines()\n","    lines = [float(line.rstrip()) for line in lines]\n","  mean = statistics.mean(lines)\n","  df['Average_accuracy_30IT'][idx] = mean\n","  df['Std_deviation'][idx] = statistics.stdev(lines, mean)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"WijLqFjZRCGf","executionInfo":{"status":"ok","timestamp":1656268008006,"user_tz":-120,"elapsed":9,"user":{"displayName":"ELA KATHERINE SHEPHERD AREVALO","userId":"06530263046701412488"}},"outputId":"cf88de4c-e75c-4b3a-8b3e-ddfa94da2de8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["     Language Emoji&hashtag Train/test        Model       Model_Specification  \\\n","0     Spanish           All      60/40  Naive Bayes               Multinomial   \n","1     Spanish           All      60/40  Naive Bayes               Multinomial   \n","2     Spanish           All      60/40  Naive Bayes               Multinomial   \n","3     Spanish           All      60/40  Naive Bayes               Multinomial   \n","4     Spanish           All      60/40  Naive Bayes                 Bernoulli   \n","...       ...           ...        ...          ...                       ...   \n","2011  English            No      80/20           LR  Lbfgs solver, standard C   \n","2012  English            No      80/20           LR     Lbfgs solver, large C   \n","2013  English            No      80/20           LR     Lbfgs solver, large C   \n","2014  English            No      80/20           LR     Lbfgs solver, large C   \n","2015  English            No      80/20           LR     Lbfgs solver, large C   \n","\n","     TF-IDF Balance  Average_accuracy_30IT  Std_deviation  \n","0       Yes     Yes                    NaN            NaN  \n","1       Yes      No                    NaN            NaN  \n","2        No     Yes                    NaN            NaN  \n","3        No      No                    NaN            NaN  \n","4       Yes     Yes                    NaN            NaN  \n","...     ...     ...                    ...            ...  \n","2011     No      No                    NaN            NaN  \n","2012    Yes     Yes                    NaN            NaN  \n","2013    Yes      No                    NaN            NaN  \n","2014     No     Yes                    NaN            NaN  \n","2015     No      No                    NaN            NaN  \n","\n","[2016 rows x 9 columns]"],"text/html":["\n","  <div id=\"df-1829931d-681e-4ddb-9c08-64aa042cb89e\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Language</th>\n","      <th>Emoji&amp;hashtag</th>\n","      <th>Train/test</th>\n","      <th>Model</th>\n","      <th>Model_Specification</th>\n","      <th>TF-IDF</th>\n","      <th>Balance</th>\n","      <th>Average_accuracy_30IT</th>\n","      <th>Std_deviation</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Spanish</td>\n","      <td>All</td>\n","      <td>60/40</td>\n","      <td>Naive Bayes</td>\n","      <td>Multinomial</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Spanish</td>\n","      <td>All</td>\n","      <td>60/40</td>\n","      <td>Naive Bayes</td>\n","      <td>Multinomial</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Spanish</td>\n","      <td>All</td>\n","      <td>60/40</td>\n","      <td>Naive Bayes</td>\n","      <td>Multinomial</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Spanish</td>\n","      <td>All</td>\n","      <td>60/40</td>\n","      <td>Naive Bayes</td>\n","      <td>Multinomial</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Spanish</td>\n","      <td>All</td>\n","      <td>60/40</td>\n","      <td>Naive Bayes</td>\n","      <td>Bernoulli</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2011</th>\n","      <td>English</td>\n","      <td>No</td>\n","      <td>80/20</td>\n","      <td>LR</td>\n","      <td>Lbfgs solver, standard C</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2012</th>\n","      <td>English</td>\n","      <td>No</td>\n","      <td>80/20</td>\n","      <td>LR</td>\n","      <td>Lbfgs solver, large C</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2013</th>\n","      <td>English</td>\n","      <td>No</td>\n","      <td>80/20</td>\n","      <td>LR</td>\n","      <td>Lbfgs solver, large C</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2014</th>\n","      <td>English</td>\n","      <td>No</td>\n","      <td>80/20</td>\n","      <td>LR</td>\n","      <td>Lbfgs solver, large C</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2015</th>\n","      <td>English</td>\n","      <td>No</td>\n","      <td>80/20</td>\n","      <td>LR</td>\n","      <td>Lbfgs solver, large C</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2016 rows Ã— 9 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1829931d-681e-4ddb-9c08-64aa042cb89e')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-1829931d-681e-4ddb-9c08-64aa042cb89e button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1829931d-681e-4ddb-9c08-64aa042cb89e');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":6}]}]}