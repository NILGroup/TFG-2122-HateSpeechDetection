{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Accuracy_excel.ipynb","provenance":[],"collapsed_sections":["MIo4952tQ8Y5"],"authorship_tag":"ABX9TyN8dXGDZlNa/nqf+1rST51M"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#CREATION OF ACCURACY RESULTS EXCEL\n","\n","This notebook's function is to take all the accuracy experiments' data from each of their .txt files and to write the average and standard deviation for each one.\n","\n","*Note: When saving or loading data from Drive, the paths are specific to my personal Drive*"],"metadata":{"id":"mdpYfXYVbN6p"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"w6ADwCHgO8RX"},"outputs":[],"source":["import statistics \n","import pandas as pd"]},{"cell_type":"code","source":["from google.colab import drive \n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_e-fjJnIPKwF","executionInfo":{"status":"ok","timestamp":1661106274201,"user_tz":-120,"elapsed":18989,"user":{"displayName":"ELA KATHERINE SHEPHERD AREVALO","userId":"06530263046701412488"}},"outputId":"721094a9-0ca9-43cd-f539-99cd664aee0d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["####Imports & functions"],"metadata":{"id":"MIo4952tQ8Y5"}},{"cell_type":"code","source":["df = pd.read_csv('/content/drive/MyDrive/TFG/data/accuracy_data/All_accuracy_std_deviation_data.csv', encoding='utf8', engine='python')"],"metadata":{"id":"sHq-UVrbQ5AM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def emojisHashtagsFile(txt):\n","  if txt == \"All\":\n","    return \"mantained\"\n","  elif txt == \"No\":\n","    return \"removed\"\n","\n","def trainTestFile(txt):\n","  if txt == \"60/40\":\n","    return \"60.040.0\"\n","  elif txt == \"70/30\":\n","    return \"70.030.0\"\n","  elif txt == \"80/20\":\n","    return \"80.020.0\"\n","\n","def trainTestFolder(txt):\n","  if txt == \"60/40\":\n","    return \"60 40\"\n","  elif txt == \"70/30\":\n","    return \"70 30\"\n","  elif txt == \"80/20\":\n","    return \"80 20\"\n","\n","def modelFile(txt):\n","  if txt == \"Naive Bayes\":\n","    return \"NB\"\n","  elif txt == \"LR\":\n","    return \"LR\"\n","  elif txt == \"SVM\":\n","    return \"SVM\"\n","\n","def modelSpecificationsFile(txt): \n","  if txt == \"Multinomial\":\n","    return \"Multinomial\"\n","  elif txt == \"Bernoulli\":\n","    return \"Bernoulli\"\n","  elif txt == \"Linear kernel, small C\":\n","    return \"linearKernel_0.1C\"\n","  elif txt == \"Linear kernel, standard C\":\n","    return \"linearKernel_1C\"\n","  elif txt == \"Linear kernel, large C\":\n","    return \"linearKernel_10C\"\n","  elif txt == \"RBF kernel, small C\":\n","    return \"rbfKernel_0.1C\"\n","  elif txt == \"RBF kernel, standard C\":\n","    return \"rbfKernel_1C\"\n","  elif txt == \"RBF kernel, large C\":\n","    return \"rbfKernel_10C\"\n","  elif txt == \"Liblinear solver, small C\":\n","    return \"liblinearSolver_0.1C\"\n","  elif txt == \"Liblinear solver, standard C\":\n","    return \"liblinearSolver_1C\"\n","  elif txt == \"Liblinear solver, large C\":\n","    return \"liblinearSolver_10C\"\n","  elif txt == \"Lbfgs solver, small C\":\n","    return \"lbfgsSolver_0.1C\"\n","  elif txt == \"Lbfgs solver, standard C\":\n","    return \"lbfgsSolver_1C\"\n","  elif txt == \"Lbfgs solver, large C\":\n","    return \"lbfgsSolver_10C\"\n","\n","def vectorizerFile(txt):\n","  if txt == \"Yes\":\n","    return \"TfidfVectorizer\"\n","  elif txt == \"No\":\n","    return \"CountVectorizer\"\n","\n","def balancedFile(txt):\n","  if txt == \"Yes\":\n","    return \"BALANCED\"\n","  elif txt == \"No\":\n","    return \"NOT_BALANCED\""],"metadata":{"id":"0zCXu1DgYDEQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Writing data in table"],"metadata":{"id":"0ng5sD3xxAzc"}},{"cell_type":"code","source":["#Each row belongs to a certain accuracy test: specific language, emoji&hashtag treatment, algorithm specification, vectorizer, train/test split and balancing of the data\n","for idx, row in df.iterrows():\n","#---------------------SET PATH TO EXTRACT DATA-------------------------------\n","  emojis_hashtags_file = emojisHashtagsFile(df['Emoji&hashtag'][idx])\n","  train_test_folder = trainTestFolder(df['Train/test'][idx])\n","  train_test_file = trainTestFile(df['Train/test'][idx])\n","  model_file = modelFile(df['Model'][idx])\n","  model_specifications_file = modelSpecificationsFile(df['Model_Specification'][idx])\n","  vectorizer_file = vectorizerFile(df['TF-IDF'][idx])\n","  balanced_file = balancedFile(df['Balance'][idx])\n","#------------------------------------------------------------\n","  path = \"/content/drive/MyDrive/TFG/data/accuracy_data/\"+ df['Language'][idx] +\"/\"+ df['Emoji&hashtag'][idx] +\"_emojis/\"+ train_test_folder +\"TT/\"+ model_file +\"_\"+ df['Language'][idx].lower() +\"_\"+ emojis_hashtags_file +\"_\"+ train_test_file +\"TrainTest_\"+ model_specifications_file +\"_\"+ vectorizer_file +\"_\"+ balanced_file +\".txt\"\n","  with open(path) as f:\n","    lines = f.readlines()\n","    if len(lines) != 30:\n","      lines.pop()\n","    lines = [float(line.rstrip()) for line in lines]\n","  mean = statistics.mean(lines)\n","  df['Average_accuracy_30IT'][idx] = mean\n","  df['Std_deviation'][idx] = statistics.stdev(lines, mean)\n","df.to_csv('/content/drive/MyDrive/TFG/data/accuracy_data/Accuracy_data_complete.csv', index=False)  "],"metadata":{"id":"CXKYW_4Q1FWp"},"execution_count":null,"outputs":[]}]}